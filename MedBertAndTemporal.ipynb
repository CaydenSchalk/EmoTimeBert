{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T02:34:20.017372608Z",
     "start_time": "2026-01-30T02:34:18.538553658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from models.emotimebert import EmotionalTimeBert\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from data_handling.datasets.empathetic_dialogues import EmpatheticDialoguesDataset\n",
    "from data_handling.data_cleaning.empathetic_dialogues import load_empath_conversations, load_empath_test_conversations\n",
    "from data_handling.data_cleaning.meld import load_meld_dfs, load_meld_split\n",
    "from utils.utils import train_model, validate_model, test_model, collate_conversations, create_new_run_dir, save_table_as_csv\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "TRAINING = False\n"
   ],
   "id": "7d4315d341d52ce7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cayden/miniconda3/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T02:34:20.067097436Z",
     "start_time": "2026-01-30T02:34:20.021559791Z"
    }
   },
   "cell_type": "code",
   "source": "base_save_location = create_new_run_dir(new_dir=TRAINING)",
   "id": "e078b201fdbb57b3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T02:34:22.941173840Z",
     "start_time": "2026-01-30T02:34:20.069598061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conversations, val_conversations, emotion_labels, emotion_to_id = load_empath_conversations()\n",
    "\n",
    "meld_data = load_meld_split(\"train\")\n",
    "meld_data"
   ],
   "id": "5b3e6876b0e7b8f2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      serial_number                                          utterance  \\\n",
       "0                 1  also I was the point person on my companys tr...   \n",
       "1                 2                   You mustve had your hands full.   \n",
       "2                 3                            That I did. That I did.   \n",
       "3                 4      So lets talk a little bit about your duties.   \n",
       "4                 5                             My duties?  All right.   \n",
       "...             ...                                                ...   \n",
       "9984          10474                                         You or me?   \n",
       "9985          10475  I got it. Uh, Joey, women don't have Adam's ap...   \n",
       "9986          10476               You guys are messing with me, right?   \n",
       "9987          10477                                              Yeah.   \n",
       "9988          10478  That was a good one. For a second there, I was...   \n",
       "\n",
       "              speaker  emotion  dialogue_id  utterance_id  season  episode  \\\n",
       "0            Chandler        0            0             0       8       21   \n",
       "1     The Interviewer        0            0             1       8       21   \n",
       "2            Chandler        0            0             2       8       21   \n",
       "3     The Interviewer        0            0             3       8       21   \n",
       "4            Chandler        1            0             4       8       21   \n",
       "...               ...      ...          ...           ...     ...      ...   \n",
       "9984         Chandler        0         1038            13       2        3   \n",
       "9985             Ross        0         1038            14       2        3   \n",
       "9986             Joey        1         1038            15       2        3   \n",
       "9987              All        0         1038            16       2        3   \n",
       "9988             Joey        5         1038            17       2        3   \n",
       "\n",
       "     start_time end_time  \n",
       "0        976059   981731  \n",
       "1        981940   983442  \n",
       "2        983442   986389  \n",
       "3        986820   989572  \n",
       "4        994452  1000917  \n",
       "...         ...      ...  \n",
       "9984      48173    50799  \n",
       "9985      51009    53594  \n",
       "9986      60518    63520  \n",
       "9987      65398    67274  \n",
       "9988      68401    72071  \n",
       "\n",
       "[9989 rows x 10 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_number</th>\n",
       "      <th>utterance</th>\n",
       "      <th>speaker</th>\n",
       "      <th>emotion</th>\n",
       "      <th>dialogue_id</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>also I was the point person on my companys tr...</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>976059</td>\n",
       "      <td>981731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>You mustve had your hands full.</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>981940</td>\n",
       "      <td>983442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>That I did. That I did.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>983442</td>\n",
       "      <td>986389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>So lets talk a little bit about your duties.</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>986820</td>\n",
       "      <td>989572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>My duties?  All right.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>994452</td>\n",
       "      <td>1000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>10474</td>\n",
       "      <td>You or me?</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>0</td>\n",
       "      <td>1038</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>48173</td>\n",
       "      <td>50799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>10475</td>\n",
       "      <td>I got it. Uh, Joey, women don't have Adam's ap...</td>\n",
       "      <td>Ross</td>\n",
       "      <td>0</td>\n",
       "      <td>1038</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>51009</td>\n",
       "      <td>53594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>10476</td>\n",
       "      <td>You guys are messing with me, right?</td>\n",
       "      <td>Joey</td>\n",
       "      <td>1</td>\n",
       "      <td>1038</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>60518</td>\n",
       "      <td>63520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>10477</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>All</td>\n",
       "      <td>0</td>\n",
       "      <td>1038</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>65398</td>\n",
       "      <td>67274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>10478</td>\n",
       "      <td>That was a good one. For a second there, I was...</td>\n",
       "      <td>Joey</td>\n",
       "      <td>5</td>\n",
       "      <td>1038</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>68401</td>\n",
       "      <td>72071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9989 rows × 10 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "dataset = EmpatheticDialoguesDataset(conversations, tokenizer)\n",
    "val_dataset = EmpatheticDialoguesDataset(val_conversations, tokenizer)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=40,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    # pin_memory=True,\n",
    "    # persistent_workers=True,\n",
    "    collate_fn=lambda x: collate_conversations(x, tokenizer),\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=40,\n",
    "    shuffle=False, # future me, keep it false, helps reproduce results\n",
    "    num_workers=8,\n",
    "    #pin_memory=True,\n",
    "    # persistent_workers=True,\n",
    "    collate_fn=lambda x: collate_conversations(x, tokenizer),\n",
    ")\n"
   ],
   "id": "8b78505d634dec8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    print(\"Device:\", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA Enabled!\")\n",
    "\n",
    "model = EmotionalTimeBert(\"./medbert_4_epochs\", num_labels=len(emotion_labels)).to(device)\n",
    "\n",
    "if not TRAINING:\n",
    "    model.load_state_dict(torch.load(f\"{base_save_location}/model.pt\")) #  emotional_time_bert_GRU_To_Show5.pt\"\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {\"params\": model.encoder.encoder.layer[-2:].parameters(), \"lr\": 1e-5},\n",
    "    {\"params\": model.temporal_transformer.parameters(), \"lr\": 3e-4},\n",
    "    {\"params\": model.time_embed.parameters(), \"lr\": 3e-4},\n",
    "    {\"params\": model.speakers_embed.parameters(), \"lr\": 3e-4},\n",
    "    {\"params\": model.head_emotions.parameters(), \"lr\": 3e-4},\n",
    "])"
   ],
   "id": "d460bfceeea1d306",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_step_losses = []\n",
    "val_step_losses = []\n",
    "global_steps = []\n",
    "val_steps = []\n",
    "\n",
    "\n",
    "if TRAINING:\n",
    "    num_of_epochs = 5\n",
    "    step = 0\n",
    "    for epoch in range(num_of_epochs):\n",
    "        progress_bar = tqdm(loader, total=len(loader))\n",
    "        avg_loss, step = train_model(model, optimizer, device, criterion=criterion, bar=progress_bar, train_step_losses=train_step_losses, global_steps=global_steps, start_step=step)\n",
    "        validate_progress = tqdm(val_loader, total=len(val_loader))\n",
    "        val_loss, val_f1, step = validate_model(model, device, criterion=criterion, bar=validate_progress, val_step_losses=val_step_losses, val_steps=val_steps, start_step=step)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: train loss = {avg_loss:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}: val loss   = {val_loss:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}: val F1     = {val_f1:.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), f\"{base_save_location}/model.pt\")\n",
    "    save_table_as_csv(global_steps, f\"{base_save_location}/global_steps.csv\")\n",
    "    save_table_as_csv(train_step_losses, f\"{base_save_location}/train_step_losses.csv\")\n",
    "    save_table_as_csv(val_step_losses, f\"{base_save_location}/val_step_losses.csv\")\n",
    "    save_table_as_csv(val_steps, f\"{base_save_location}/val_steps.csv\")\n",
    "\n"
   ],
   "id": "a8aa3662b8da5857",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if TRAINING:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(global_steps, train_step_losses, alpha=0.4, label=\"Train (per batch)\")\n",
    "    plt.plot(val_steps, val_step_losses, alpha=0.8, label=\"Val (per batch)\")\n",
    "\n",
    "    plt.xlabel(\"Training Step\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Per-batch Training & Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{base_save_location}/Unsmoothed.png\")"
   ],
   "id": "e28e43e34a486ef9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def ema(values, beta=0.98):\n",
    "    smoothed = []\n",
    "    avg = values[0]\n",
    "    for v in values:\n",
    "        avg = beta * avg + (1 - beta) * v\n",
    "        smoothed.append(avg)\n",
    "    return smoothed\n",
    "\n",
    "if TRAINING:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(global_steps, ema(train_step_losses), label=\"Train\")\n",
    "    plt.plot(val_steps, ema(val_step_losses), label=\"Val\")\n",
    "    plt.xlabel(\"Training Step\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Per-step Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{base_save_location}/Smoothed.png\")"
   ],
   "id": "ba908e534550495",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_conversations = load_empath_test_conversations(emotion_to_id)",
   "id": "4d05dd7df7551fc3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_dataset = EmpatheticDialoguesDataset(test_conversations, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    collate_fn=lambda x: collate_conversations(x, tokenizer)\n",
    ")"
   ],
   "id": "69adeeae8ad206b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_f1 = test_model(\n",
    "    model=model,\n",
    "    dataloader=test_loader,\n",
    "    device=device,\n",
    "    emotion_labels=emotion_labels,\n",
    "    save_results=True,\n",
    "    save_dir=f\"{base_save_location}/classification_report.csv\",\n",
    ")\n",
    "# also look into bert's special keywords"
   ],
   "id": "25ece79283d53166",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def ablation(model, dataloader, device, ablate):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            utterance_mask = batch[\"utterance_mask\"].to(device)\n",
    "\n",
    "            timestamps = batch[\"timestamps\"].to(device)\n",
    "            speakers = batch[\"speakers\"].to(device)\n",
    "\n",
    "            if ablate == \"time_zero\":\n",
    "                timestamps = torch.zeros_like(timestamps)\n",
    "            elif ablate == \"time_shuffle\":\n",
    "                timestamps = timestamps[torch.randperm(timestamps.size(0))]\n",
    "            elif ablate == \"speaker_zero\":\n",
    "                speakers = torch.zeros_like(speakers)\n",
    "\n",
    "            logits = model(\n",
    "                input_ids, attention_mask,\n",
    "                timestamps, speakers,\n",
    "                labels, utterance_mask\n",
    "            )\n",
    "\n",
    "            preds = logits.argmax(-1)\n",
    "            mask = labels != -1\n",
    "\n",
    "            all_preds.append(preds[mask].cpu())\n",
    "            all_labels.append(labels[mask].cpu())\n",
    "\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    return f1_score(all_labels, all_preds, average=\"macro\")"
   ],
   "id": "741b37b79604c38a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(\"Normal:\", ablation(model, val_loader, device, \"none\"))",
   "id": "15bee95eb6e79079",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(\"Time zero:\", ablation(model, val_loader, device, \"time_zero\"))",
   "id": "21025e2b218b3ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(\"Time shuffle:\", ablation(model, val_loader, device, \"time_shuffle\"))",
   "id": "c73528b233af0489",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(\"Speaker zero:\", ablation(model, val_loader, device, \"speaker_zero\"))",
   "id": "2d3e534d54b90e41",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
