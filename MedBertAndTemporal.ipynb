{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T01:08:36.912510474Z",
     "start_time": "2026-01-30T01:08:35.453100266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from models.emotimebert import EmotionalTimeBert\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from data_handling.datasets.empathetic_dialogues import EmpatheticDialoguesDataset\n",
    "from data_handling.data_cleaning.empathetic_dialogues import load_empath_conversations, load_empath_test_conversations\n",
    "from utils.utils import train_model, validate_model, test_model, collate_conversations, create_new_run_dir, save_table_as_csv\n",
    "from pathlib import Path\n",
    "import re\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "TRAINING = False\n"
   ],
   "id": "7d4315d341d52ce7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cayden/miniconda3/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T01:08:36.959353619Z",
     "start_time": "2026-01-30T01:08:36.913058059Z"
    }
   },
   "cell_type": "code",
   "source": "base_save_location = create_new_run_dir(new_dir=TRAINING)",
   "id": "e078b201fdbb57b3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T01:08:39.845419828Z",
     "start_time": "2026-01-30T01:08:36.961603761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conversations, val_conversations, emotion_labels, emotion_to_id = load_empath_conversations()\n"
   ],
   "id": "5b3e6876b0e7b8f2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T01:08:40.270547520Z",
     "start_time": "2026-01-30T01:08:39.889554304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "dataset = EmpatheticDialoguesDataset(conversations, tokenizer)\n",
    "val_dataset = EmpatheticDialoguesDataset(val_conversations, tokenizer)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=40,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    # pin_memory=True,\n",
    "    # persistent_workers=True,\n",
    "    collate_fn=lambda x: collate_conversations(x, tokenizer),\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=40,\n",
    "    shuffle=False, # future me, keep it false, helps reproduce results\n",
    "    num_workers=8,\n",
    "    #pin_memory=True,\n",
    "    # persistent_workers=True,\n",
    "    collate_fn=lambda x: collate_conversations(x, tokenizer),\n",
    ")\n"
   ],
   "id": "8b78505d634dec8a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T01:08:40.813054648Z",
     "start_time": "2026-01-30T01:08:40.275332537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    print(\"Device:\", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA Enabled!\")\n",
    "\n",
    "model = EmotionalTimeBert(\"./medbert_4_epochs\", num_labels=len(emotion_labels)).to(device)\n",
    "\n",
    "if not TRAINING:\n",
    "    model.load_state_dict(torch.load(f\"{base_save_location}/model.pt\")) #  emotional_time_bert_GRU_To_Show5.pt\"\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {\"params\": model.encoder.encoder.layer[-2:].parameters(), \"lr\": 1e-5},\n",
    "    {\"params\": model.temporal_transformer.parameters(), \"lr\": 3e-4},\n",
    "    {\"params\": model.time_embed.parameters(), \"lr\": 3e-4},\n",
    "    {\"params\": model.speakers_embed.parameters(), \"lr\": 3e-4},\n",
    "    {\"params\": model.head_emotions.parameters(), \"lr\": 3e-4},\n",
    "])"
   ],
   "id": "d460bfceeea1d306",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: NVIDIA GeForce RTX 5080\n",
      "CUDA Enabled!\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T01:08:40.918952680Z",
     "start_time": "2026-01-30T01:08:40.861661003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_step_losses = []\n",
    "val_step_losses = []\n",
    "global_steps = []\n",
    "val_steps = []\n",
    "\n",
    "\n",
    "if TRAINING:\n",
    "    num_of_epochs = 5\n",
    "    step = 0\n",
    "    for epoch in range(num_of_epochs):\n",
    "        progress_bar = tqdm(loader, total=len(loader))\n",
    "        avg_loss, step = train_model(model, optimizer, device, criterion=criterion, bar=progress_bar, train_step_losses=train_step_losses, global_steps=global_steps, start_step=step)\n",
    "        validate_progress = tqdm(val_loader, total=len(val_loader))\n",
    "        val_loss, val_f1, step = validate_model(model, device, criterion=criterion, bar=validate_progress, val_step_losses=val_step_losses, val_steps=val_steps, start_step=step)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: train loss = {avg_loss:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}: val loss   = {val_loss:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}: val F1     = {val_f1:.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), f\"{base_save_location}/model.pt\")\n",
    "    save_table_as_csv(global_steps, f\"{base_save_location}/global_steps.csv\")\n",
    "    save_table_as_csv(train_step_losses, f\"{base_save_location}/train_step_losses.csv\")\n",
    "    save_table_as_csv(val_step_losses, f\"{base_save_location}/val_step_losses.csv\")\n",
    "    save_table_as_csv(val_steps, f\"{base_save_location}/val_steps.csv\")\n",
    "\n"
   ],
   "id": "a8aa3662b8da5857",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T01:08:40.972958025Z",
     "start_time": "2026-01-30T01:08:40.921528742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if TRAINING:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(global_steps, train_step_losses, alpha=0.4, label=\"Train (per batch)\")\n",
    "    plt.plot(val_steps, val_step_losses, alpha=0.8, label=\"Val (per batch)\")\n",
    "\n",
    "    plt.xlabel(\"Training Step\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Per-batch Training & Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{base_save_location}/Unsmoothed.png\")"
   ],
   "id": "e28e43e34a486ef9",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T01:08:41.031855974Z",
     "start_time": "2026-01-30T01:08:40.975460400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ema(values, beta=0.98):\n",
    "    smoothed = []\n",
    "    avg = values[0]\n",
    "    for v in values:\n",
    "        avg = beta * avg + (1 - beta) * v\n",
    "        smoothed.append(avg)\n",
    "    return smoothed\n",
    "\n",
    "if TRAINING:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(global_steps, ema(train_step_losses), label=\"Train\")\n",
    "    plt.plot(val_steps, ema(val_step_losses), label=\"Val\")\n",
    "    plt.xlabel(\"Training Step\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Per-step Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{base_save_location}/Smoothed.png\")"
   ],
   "id": "ba908e534550495",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T01:08:41.631638903Z",
     "start_time": "2026-01-30T01:08:41.035719221Z"
    }
   },
   "cell_type": "code",
   "source": "test_conversations = load_empath_test_conversations(emotion_to_id)",
   "id": "4d05dd7df7551fc3",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T01:08:41.734948573Z",
     "start_time": "2026-01-30T01:08:41.679968844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_dataset = EmpatheticDialoguesDataset(test_conversations, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    collate_fn=lambda x: collate_conversations(x, tokenizer)\n",
    ")"
   ],
   "id": "69adeeae8ad206b6",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T01:08:54.470476602Z",
     "start_time": "2026-01-30T01:08:41.739188391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_f1 = test_model(\n",
    "    model=model,\n",
    "    dataloader=test_loader,\n",
    "    device=device,\n",
    "    emotion_labels=emotion_labels,\n",
    "    save_results=True,\n",
    "    save_dir=f\"{base_save_location}/classification_report.csv\",\n",
    ")\n",
    "# also look into bert's special keywords"
   ],
   "id": "25ece79283d53166",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T01:08:54.573748706Z",
     "start_time": "2026-01-30T01:08:54.516512639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ablation(model, dataloader, device, ablate):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            utterance_mask = batch[\"utterance_mask\"].to(device)\n",
    "\n",
    "            timestamps = batch[\"timestamps\"].to(device)\n",
    "            speakers = batch[\"speakers\"].to(device)\n",
    "\n",
    "            if ablate == \"time_zero\":\n",
    "                timestamps = torch.zeros_like(timestamps)\n",
    "            elif ablate == \"time_shuffle\":\n",
    "                timestamps = timestamps[torch.randperm(timestamps.size(0))]\n",
    "            elif ablate == \"speaker_zero\":\n",
    "                speakers = torch.zeros_like(speakers)\n",
    "\n",
    "            logits = model(\n",
    "                input_ids, attention_mask,\n",
    "                timestamps, speakers,\n",
    "                labels, utterance_mask\n",
    "            )\n",
    "\n",
    "            preds = logits.argmax(-1)\n",
    "            mask = labels != -1\n",
    "\n",
    "            all_preds.append(preds[mask].cpu())\n",
    "            all_labels.append(labels[mask].cpu())\n",
    "\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    return f1_score(all_labels, all_preds, average=\"macro\")"
   ],
   "id": "741b37b79604c38a",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T01:09:07.293832079Z",
     "start_time": "2026-01-30T01:08:54.576230691Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Normal:\", ablation(model, val_loader, device, \"none\"))",
   "id": "15bee95eb6e79079",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal: 0.45721292987638296\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T01:09:19.779501251Z",
     "start_time": "2026-01-30T01:09:07.353353480Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Time zero:\", ablation(model, val_loader, device, \"time_zero\"))",
   "id": "21025e2b218b3ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time zero: 0.30866959758379153\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T01:09:32.290739259Z",
     "start_time": "2026-01-30T01:09:19.825657605Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Time shuffle:\", ablation(model, val_loader, device, \"time_shuffle\"))",
   "id": "c73528b233af0489",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time shuffle: 0.45872878781524007\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T01:09:44.799843172Z",
     "start_time": "2026-01-30T01:09:32.337888049Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Speaker zero:\", ablation(model, val_loader, device, \"speaker_zero\"))",
   "id": "2d3e534d54b90e41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker zero: 0.45293499501246337\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
