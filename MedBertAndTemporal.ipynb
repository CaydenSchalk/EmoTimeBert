{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T05:06:36.721420723Z",
     "start_time": "2026-02-01T05:06:35.340161034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import pprint as pp\n",
    "from utils.param_objects import EmpatheticDialogueParams, MELDParams\n",
    "from models.emotimebert import EmotionalTimeBert, DatasetMode\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from data_handling.datasets.empathetic_dialogues import EmpatheticDialoguesDataset\n",
    "from data_handling.datasets.meld import MELDDataset\n",
    "from data_handling.data_cleaning.empathetic_dialogues import load_empath_conversations, load_empath_test_conversations\n",
    "from data_handling.data_cleaning.meld import load_meld_dfs, load_meld_split, load_meld_conversations, load_meld_test_conversations, emotion_id_to_label, label_to_emotion_id\n",
    "from utils.utils import train_model, validate_model, test_model, collate_conversations, create_new_run_dir, save_table_as_csv, compute_class_weights, FocalLoss\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "TRAINING = False\n"
   ],
   "id": "7d4315d341d52ce7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cayden/miniconda3/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T05:06:36.766047806Z",
     "start_time": "2026-02-01T05:06:36.721826086Z"
    }
   },
   "cell_type": "code",
   "source": "base_save_location = create_new_run_dir(new_dir=TRAINING)",
   "id": "e078b201fdbb57b3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T05:06:39.528832658Z",
     "start_time": "2026-02-01T05:06:36.767233115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conversations, val_conversations, emotion_labels, emotion_to_id = load_empath_conversations()\n",
    "meld_data, val_data = load_meld_dfs()\n",
    "meld_conversations, val_meld_conversations, meld_emotions, meld_labels = load_meld_conversations()"
   ],
   "id": "5b3e6876b0e7b8f2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T05:06:39.837994617Z",
     "start_time": "2026-02-01T05:06:39.573712444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "dataset = MELDDataset(meld_conversations, tokenizer)\n",
    "val_dataset = MELDDataset(val_meld_conversations, tokenizer)\n"
   ],
   "id": "8b78505d634dec8a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T05:06:39.885431267Z",
     "start_time": "2026-02-01T05:06:39.839124337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# loader = DataLoader(\n",
    "#     dataset,\n",
    "#     batch_size=16,\n",
    "#     shuffle=True,\n",
    "#     num_workers=8,\n",
    "#     # pin_memory=True,\n",
    "#     # persistent_workers=True,\n",
    "#     collate_fn=lambda x: collate_conversations(x, tokenizer),\n",
    "# )\n",
    "#\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False, # future me, keep it false, helps reproduce results\n",
    "    num_workers=8,\n",
    "    #pin_memory=True,\n",
    "    # persistent_workers=True,\n",
    "    collate_fn=lambda x: collate_conversations(x, tokenizer),\n",
    ")\n",
    "\n",
    "RARE_EMOTIONS = {\n",
    "    label_to_emotion_id[\"fear\"],\n",
    "    label_to_emotion_id[\"joy\"],\n",
    "    label_to_emotion_id[\"disgust\"],\n",
    "}\n",
    "\n",
    "def conversation_weight(item, rare_emotions, boost=10.0):\n",
    "    labels = item[\"labels\"]\n",
    "    if any(lbl.item() in rare_emotions for lbl in labels if lbl.item() != -1):\n",
    "        return boost\n",
    "    return 1.0\n",
    "\n",
    "train_weights = [\n",
    "    conversation_weight(item, RARE_EMOTIONS)\n",
    "    for item in dataset\n",
    "]\n",
    "\n",
    "train_sampler = WeightedRandomSampler(\n",
    "    weights=train_weights,\n",
    "    num_samples=len(dataset),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=16,\n",
    "    # shuffle=True,\n",
    "    num_workers=8,\n",
    "    sampler=train_sampler,\n",
    "    collate_fn=lambda x: collate_conversations(x, tokenizer)\n",
    ")\n",
    "\n",
    "# val_weights = [\n",
    "#     conversation_weight(item, RARE_EMOTIONS)\n",
    "#     for item in val_dataset\n",
    "# ]\n",
    "#\n",
    "# val_sampler = WeightedRandomSampler(\n",
    "#     weights=val_weights,\n",
    "#     num_samples=len(val_dataset),\n",
    "#     replacement=True\n",
    "# )\n",
    "#\n",
    "# val_loader = DataLoader(\n",
    "#     val_dataset,\n",
    "#     batch_size=16,\n",
    "#     # shuffle=False, # future me, keep it false, helps reproduce results\n",
    "#     num_workers=8,\n",
    "#     sampler=val_sampler,\n",
    "#     #pin_memory=True,\n",
    "#     # persistent_workers=True,\n",
    "#     collate_fn=lambda x: collate_conversations(x, tokenizer),\n",
    "# )"
   ],
   "id": "2aa4e322bd8ce239",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T05:06:39.935140627Z",
     "start_time": "2026-02-01T05:06:39.886761810Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "fa20e22392fecfa1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T05:06:40.788978752Z",
     "start_time": "2026-02-01T05:06:39.936402652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    print(\"Device:\", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA Enabled!\")\n",
    "\n",
    "meld_params = MELDParams(num_labels=len(meld_emotions))\n",
    "\n",
    "model = EmotionalTimeBert(\"./medbert_4_epochs\", meld_params=meld_params).to(device)\n",
    "\n",
    "if not TRAINING:\n",
    "    # model.load_state_dict(torch.load(f\"{base_save_location}/model.pt\")) #  emotional_time_bert_GRU_To_Show5.pt\"\n",
    "    checkpoint = torch.load(f\"{base_save_location}/model.pt\")\n",
    "    model.load_state_dict(checkpoint[\"model_state\"])\n",
    "    model.use_gru = checkpoint[\"use_gru\"]\n",
    "\n",
    "weights = compute_class_weights(loader, len(meld_emotions), device)\n",
    "\n",
    "# criterion = torch.nn.CrossEntropyLoss(\n",
    "#     weight=weights,\n",
    "#     ignore_index=-1\n",
    "# )\n",
    "\n",
    "criterion = FocalLoss(\n",
    "    alpha=weights,\n",
    "    gamma=2.0,\n",
    "    ignore_index=-1\n",
    ")\n",
    "\n",
    "adam_params = [\n",
    "    {\"params\": model.encoder.encoder.layer[-6:].parameters(), \"lr\": 1e-5},\n",
    "    {\"params\": model.temporal_transformer.parameters(), \"lr\": 3e-4},\n",
    "\n",
    "    {\"params\": model.speakers_embed.parameters(), \"lr\": 3e-4},\n",
    "]\n",
    "\n",
    "if model.dataset_mode == DatasetMode.BOTH:\n",
    "    adam_params.append({\"params\": model.head_empath.parameters(), \"lr\": 3e-4})\n",
    "    adam_params.append({\"params\": model.head_meld.parameters(), \"lr\": 3e-4})\n",
    "    adam_params.append({\"params\": model.time_embed.parameters(), \"lr\": 3e-4})\n",
    "elif model.dataset_mode == DatasetMode.MELD:\n",
    "    adam_params.append({\"params\": model.head_meld.parameters(), \"lr\": 1e-4})\n",
    "    adam_params.append({\"params\": model.time_proj.parameters(), \"lr\": 1e-4})\n",
    "else:\n",
    "    adam_params.append({\"params\": model.head_empath.parameters(), \"lr\": 3e-4})\n",
    "    adam_params.append({\"params\": model.time_embed.parameters(), \"lr\": 3e-4})\n",
    "\n",
    "optimizer = torch.optim.AdamW(adam_params)"
   ],
   "id": "d460bfceeea1d306",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at ./medbert_4_epochs and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: NVIDIA GeForce RTX 5080\n",
      "CUDA Enabled!\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T05:06:42.107327485Z",
     "start_time": "2026-02-01T05:06:42.060797900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_step_losses = []\n",
    "val_step_losses = []\n",
    "global_steps = []\n",
    "val_steps = []\n",
    "val_macro_f1 = []\n",
    "val_macro_f1_steps = []\n",
    "best_f1 = 0\n",
    "\n",
    "if TRAINING:\n",
    "    num_of_epochs = 15\n",
    "    step = 0\n",
    "    for epoch in range(num_of_epochs):\n",
    "        progress_bar = tqdm(loader, total=len(loader))\n",
    "        avg_loss, step = train_model(model, optimizer, device, criterion=criterion, bar=progress_bar, train_step_losses=train_step_losses, global_steps=global_steps, start_step=step)\n",
    "        validate_progress = tqdm(val_loader, total=len(val_loader))\n",
    "        val_loss, val_f1, step, report = validate_model(model, device, criterion=criterion, bar=validate_progress, val_step_losses=val_step_losses, val_steps=val_steps, start_step=step)\n",
    "\n",
    "        dead_classes = [\n",
    "            cls for cls, stats in report.items()\n",
    "            if isinstance(stats, dict)\n",
    "            and \"recall\" in stats\n",
    "            and stats[\"recall\"] < 0.02\n",
    "        ]\n",
    "\n",
    "        alive_ratio = 1 - len(dead_classes) / len(meld_emotions)\n",
    "        if alive_ratio >= 0.80 and not model.use_gru:\n",
    "            model.use_gru = True\n",
    "            print(\"Enough classes are alive, enabled GRU\")\n",
    "        elif alive_ratio < 0.80:\n",
    "            print(\"Not enough classes are alive yet\", emotion_id_to_label[np.array(dead_classes).astype(int)])\n",
    "\n",
    "        val_macro_f1.append(val_f1)\n",
    "        val_macro_f1_steps.append(step)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: train loss = {avg_loss:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}: val loss   = {val_loss:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}: val F1     = {val_f1:.4f}\")\n",
    "\n",
    "        # if val_f1 > best_f1:\n",
    "        #     best_f1 = val_f1\n",
    "        # else:\n",
    "        #     break\n",
    "\n",
    "    torch.save({\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"use_gru\": model.use_gru,\n",
    "        \"alpha\": model.alpha if hasattr(model, \"alpha\") else None,\n",
    "    }, f\"{base_save_location}/model.pt\")\n",
    "    save_table_as_csv(global_steps, f\"{base_save_location}/global_steps.csv\")\n",
    "    save_table_as_csv(train_step_losses, f\"{base_save_location}/train_step_losses.csv\")\n",
    "    save_table_as_csv(val_step_losses, f\"{base_save_location}/val_step_losses.csv\")\n",
    "    save_table_as_csv(val_steps, f\"{base_save_location}/val_steps.csv\")\n",
    "    save_table_as_csv(val_macro_f1, f\"{base_save_location}/val_macro_f1.csv\")\n",
    "    save_table_as_csv(val_macro_f1_steps, f\"{base_save_location}/val_macro_f1_steps.csv\")\n",
    "\n"
   ],
   "id": "a8aa3662b8da5857",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T05:06:42.158758542Z",
     "start_time": "2026-02-01T05:06:42.108377910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if TRAINING:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(global_steps, train_step_losses, alpha=0.4, label=\"Train (per batch)\")\n",
    "    plt.plot(val_steps, val_step_losses, alpha=0.8, label=\"Val (per batch)\")\n",
    "    plt.plot(val_macro_f1_steps, val_macro_f1, alpha=1, label=\"Validation F1\")\n",
    "\n",
    "    plt.xlabel(\"Training Step\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Per-batch Training & Validation Loss & Macro F1\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{base_save_location}/Unsmoothed.png\")\n"
   ],
   "id": "e28e43e34a486ef9",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T05:06:42.211441216Z",
     "start_time": "2026-02-01T05:06:42.159717860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ema(values, beta=0.98):\n",
    "    smoothed = []\n",
    "    avg = values[0]\n",
    "    for v in values:\n",
    "        avg = beta * avg + (1 - beta) * v\n",
    "        smoothed.append(avg)\n",
    "    return smoothed\n",
    "\n",
    "if TRAINING:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(global_steps, ema(train_step_losses), label=\"Train\")\n",
    "    plt.plot(val_steps, ema(val_step_losses), label=\"Val\")\n",
    "    plt.plot(val_macro_f1_steps, ema(val_macro_f1), alpha=1, label=\"Macro F1\")\n",
    "    plt.xlabel(\"Training Step\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Per-step Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{base_save_location}/Smoothed.png\")"
   ],
   "id": "ba908e534550495",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T05:06:42.268546809Z",
     "start_time": "2026-02-01T05:06:42.213062450Z"
    }
   },
   "cell_type": "code",
   "source": "test_conversations = load_meld_test_conversations(emotion_to_id)",
   "id": "4d05dd7df7551fc3",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T05:06:42.313657867Z",
     "start_time": "2026-02-01T05:06:42.268794298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_dataset = MELDDataset(test_conversations, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    collate_fn=lambda x: collate_conversations(x, tokenizer)\n",
    ")"
   ],
   "id": "69adeeae8ad206b6",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T05:06:45.031166218Z",
     "start_time": "2026-02-01T05:06:42.315086970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_f1 = test_model(\n",
    "    model=model,\n",
    "    dataloader=test_loader,\n",
    "    device=device,\n",
    "    emotion_labels=meld_labels,\n",
    "    save_results=True,\n",
    "    save_dir=f\"{base_save_location}/classification_report.csv\",\n",
    ")\n",
    "# also look into bert's special keywords"
   ],
   "id": "25ece79283d53166",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/9 [00:00<?, ?it/s]/home/cayden/miniconda3/lib/python3.13/site-packages/torch/nn/modules/transformer.py:515: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  output = torch._nested_tensor_from_mask(\n",
      "Testing: 100%|██████████| 9/9 [00:02<00:00,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro F1: 0.4259\n",
      "\n",
      "Per-emotion results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral      0.741     0.807     0.772      1256\n",
      "    surprise      0.490     0.616     0.546       281\n",
      "        fear      0.108     0.160     0.129        50\n",
      "    surprise      0.346     0.264     0.300       208\n",
      "     sadness      0.608     0.502     0.550       402\n",
      "         joy      0.367     0.162     0.224        68\n",
      "     disgust      0.498     0.426     0.459       345\n",
      "\n",
      "    accuracy                          0.616      2610\n",
      "   macro avg      0.451     0.420     0.426      2610\n",
      "weighted avg      0.608     0.616     0.608      2610\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T05:06:46.286604166Z",
     "start_time": "2026-02-01T05:06:46.241021720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ablation(model, dataloader, device, ablate):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            utterance_mask = batch[\"utterance_mask\"].to(device)\n",
    "\n",
    "            timestamps = batch[\"timestamps\"].to(device)\n",
    "            speakers = batch[\"speakers\"].to(device)\n",
    "\n",
    "            if ablate == \"time_zero\":\n",
    "                timestamps = torch.zeros_like(timestamps)\n",
    "            elif ablate == \"time_shuffle\":\n",
    "                # timestamps = timestamps[torch.randperm(timestamps.size(0))]\n",
    "                perm = torch.argsort(torch.rand_like(timestamps.float()), dim=1)\n",
    "                timestamps = torch.gather(timestamps, 1, perm)\n",
    "            elif ablate == \"speaker_zero\":\n",
    "                speakers = torch.zeros_like(speakers)\n",
    "            elif ablate == \"turn_shuffle\":\n",
    "                B, T = timestamps.shape\n",
    "                perm = torch.argsort(torch.rand(B, T, device=timestamps.device), dim=1)\n",
    "\n",
    "                timestamps = torch.gather(timestamps, 1, perm)\n",
    "                speakers = torch.gather(speakers, 1, perm)\n",
    "                labels = torch.gather(labels, 1, perm)\n",
    "                utterance_mask = torch.gather(utterance_mask, 1, perm)\n",
    "\n",
    "            logits = model(\n",
    "                input_ids, attention_mask,\n",
    "                timestamps, speakers,\n",
    "                labels, utterance_mask\n",
    "            )\n",
    "\n",
    "            preds = logits.argmax(-1)\n",
    "            mask = labels != -1\n",
    "\n",
    "            all_preds.append(preds[mask].cpu())\n",
    "            all_labels.append(labels[mask].cpu())\n",
    "\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    return f1_score(all_labels, all_preds, average=\"macro\"), f1_score(all_labels, all_preds, average=\"micro\")"
   ],
   "id": "741b37b79604c38a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T05:06:47.500749409Z",
     "start_time": "2026-02-01T05:06:46.287654168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "normal_macro, normal_micro = ablation(model, val_loader, device, \"none\")\n",
    "print(\"Normal Macro:\", normal_macro, \"Normal Micro:\", normal_micro)"
   ],
   "id": "15bee95eb6e79079",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Macro: 0.45501421648788826 Normal Micro: 0.6023444544634806\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T05:06:49.900060255Z",
     "start_time": "2026-02-01T05:06:48.703296475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "time_zero_macro, time_zero_micro = ablation(model, val_loader, device, \"time_zero\")\n",
    "print(f\"Time Zero Macro: {time_zero_macro} Difference: {time_zero_macro - normal_macro} Time Zero Micro: {time_zero_micro} Difference: {time_zero_micro - normal_micro}\")"
   ],
   "id": "21025e2b218b3ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Zero Macro: 0.45501421648788826 Difference: 0.0 Time Zero Micro: 0.6023444544634806 Difference: 0.0\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T05:06:52.320654684Z",
     "start_time": "2026-02-01T05:06:51.106933933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "time_shuffle_macro, time_shuffle_micro = ablation(model, val_loader, device, \"time_shuffle\")\n",
    "print(f\"Time Shuffle Macro: {time_shuffle_macro} Difference: {time_shuffle_macro - normal_macro} Time Shuffle micro: {time_shuffle_micro} Difference: {time_shuffle_micro - normal_micro}\")"
   ],
   "id": "c73528b233af0489",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Shuffle Macro: 0.45501421648788826 Difference: 0.0 Time Shuffle micro: 0.6023444544634806 Difference: 0.0\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T05:06:54.756024244Z",
     "start_time": "2026-02-01T05:06:53.535710360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "speaker_zero_macro, speaker_zero_micro = ablation(model, val_loader, device, \"speaker_zero\")\n",
    "print(f\"Speaker Zero Macro: {speaker_zero_macro} Difference: {speaker_zero_macro - normal_macro} Speaker Zero Micro: {speaker_zero_micro} Difference: {speaker_zero_micro - normal_micro}\")"
   ],
   "id": "2d3e534d54b90e41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker Zero Macro: 0.49190433067360784 Difference: 0.03689011418571958 Speaker Zero Micro: 0.6194770063119928 Difference: 0.017132551848512145\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T05:06:57.184980112Z",
     "start_time": "2026-02-01T05:06:55.966031262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "turn_shuffle_macro, turn_shuffle_micro = ablation(model, val_loader, device, \"turn_shuffle\")\n",
    "print(f\"Turn Shuffle Macro: {turn_shuffle_macro} Difference: {turn_shuffle_macro - normal_macro} Turn Shuffle Micro: {turn_shuffle_micro} Difference: {turn_shuffle_micro - normal_micro}\")"
   ],
   "id": "87ecfe389e8425aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn Shuffle Macro: 0.16931658693230564 Difference: -0.28569762955558264 Turn Shuffle Micro: 0.3769161406672678 Difference: -0.2254283137962128\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T05:06:58.429265570Z",
     "start_time": "2026-02-01T05:06:58.382399624Z"
    }
   },
   "cell_type": "code",
   "source": "print(model.time_scale.item())",
   "id": "fcdc6b98e24bdaf2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10000000149011612\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T05:06:58.479307577Z",
     "start_time": "2026-02-01T05:06:58.431013527Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "612cfe10d8efe8ff",
   "outputs": [],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
