{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-18T07:24:59.921619799Z",
     "start_time": "2025-12-18T07:24:58.405930875Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from models.EmoTimeBert import EmotionalTimeBert\n",
    "from tqdm import tqdm\n",
    "from data_handling.datasets.EmpatheticDialogues import EmpatheticDialoguesDataset\n",
    "from utils.utils import train_model, validate_model, test_model, collate_conversations\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "TRAINING = False"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cayden/miniconda3/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T07:25:00.078958092Z",
     "start_time": "2025-12-18T07:24:59.922630951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "empath_data = pd.read_csv(\"empatheticdialogues/train.csv\", on_bad_lines=\"skip\")\n",
    "val_empath_data = pd.read_csv(\"empatheticdialogues/valid.csv\", on_bad_lines=\"skip\")\n",
    "grouped = empath_data.groupby(\"conv_id\")\n",
    "val_grouped = val_empath_data.groupby(\"conv_id\")\n",
    "# speaker_counts = (\n",
    "#     empath_data\n",
    "#     .groupby(\"conv_id\")[\"speaker_idx\"]\n",
    "#     .nunique()\n",
    "# )\n",
    "# speaker_counts.value_counts()"
   ],
   "id": "8ecfdd537c8878b1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T07:25:02.241727086Z",
     "start_time": "2025-12-18T07:25:00.079836566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "emotion_labels = empath_data[\"context\"].unique().tolist()\n",
    "emotion_to_id = {emotion: idx for idx, emotion in enumerate(emotion_labels)}\n",
    "\n",
    "conversations = []\n",
    "\n",
    "for conv_id, df_conv in grouped:\n",
    "    texts = df_conv[\"utterance\"].tolist()\n",
    "    # texts = (df_conv[\"prompt\"] + \"[SEP]\" + df_conv[\"utterance\"]).tolist()\n",
    "    labels = [emotion_to_id[x] for x in df_conv[\"context\"]]\n",
    "    timestamps = df_conv[\"utterance_idx\"].tolist()\n",
    "    speakers = (\n",
    "        df_conv[\"speaker_idx\"]\n",
    "        .rank(method=\"dense\")\n",
    "        .astype(int)\n",
    "        .sub(1)\n",
    "        .tolist()\n",
    "    )\n",
    "    conversations.append({\n",
    "        \"texts\": texts,\n",
    "        \"labels\": labels,\n",
    "        \"timestamps\": timestamps,\n",
    "        \"speakers\": speakers\n",
    "    })\n",
    "\n",
    "val_conversations = []\n",
    "\n",
    "for conv_id, df_conv in val_grouped:\n",
    "    texts = df_conv[\"utterance\"].tolist()\n",
    "    # texts = (df_conv[\"prompt\"] + \"[SEP]\" + df_conv[\"utterance\"]).tolist()\n",
    "    labels = [emotion_to_id[x] for x in df_conv[\"context\"]]\n",
    "    timestamps = df_conv[\"utterance_idx\"].tolist()\n",
    "    speakers = (\n",
    "        df_conv[\"speaker_idx\"]\n",
    "        .rank(method=\"dense\")\n",
    "        .astype(int)\n",
    "        .sub(1)\n",
    "        .tolist()\n",
    "    )\n",
    "    val_conversations.append({\n",
    "        \"texts\": texts,\n",
    "        \"labels\": labels,\n",
    "        \"timestamps\": timestamps,\n",
    "        \"speakers\": speakers\n",
    "    })\n"
   ],
   "id": "8033a32bfff868f1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T07:25:02.889857790Z",
     "start_time": "2025-12-18T07:25:02.344633145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "dataset = EmpatheticDialoguesDataset(conversations, tokenizer)\n",
    "val_dataset = EmpatheticDialoguesDataset(val_conversations, tokenizer)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    # pin_memory=True,\n",
    "    # persistent_workers=True,\n",
    "    collate_fn=lambda x: collate_conversations(x, tokenizer),\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False, # future me, keep it false, helps reproduce results\n",
    "    num_workers=8,\n",
    "    #pin_memory=True,\n",
    "    # persistent_workers=True,\n",
    "    collate_fn=lambda x: collate_conversations(x, tokenizer),\n",
    ")\n"
   ],
   "id": "4e3484c7e1ca5da7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T07:25:03.295625785Z",
     "start_time": "2025-12-18T07:25:02.911551698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    print(\"Device:\", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA Enabled!\")\n",
    "\n",
    "model = EmotionalTimeBert(\"./medbert_4_epochs\", num_labels=len(emotion_labels)).to(device)\n",
    "\n",
    "if not TRAINING:\n",
    "    model.load_state_dict(torch.load(\"emotional_time_bert_5_to_show.pt\"))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {\"params\": model.encoder.encoder.layer[-2:].parameters(), \"lr\": 1e-5},\n",
    "    {\"params\": model.temporal_transformer.parameters(), \"lr\": 3e-4},\n",
    "    {\"params\": model.time_embed.parameters(), \"lr\": 3e-4},\n",
    "    {\"params\": model.speakers_embed.parameters(), \"lr\": 3e-4},\n",
    "    {\"params\": model.head_emotions.parameters(), \"lr\": 3e-4},\n",
    "])"
   ],
   "id": "3a512845921c6861",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at ./medbert_4_epochs and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: NVIDIA GeForce RTX 5080\n",
      "CUDA Enabled!\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T07:25:03.301646062Z",
     "start_time": "2025-12-18T07:25:03.296300448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if TRAINING:\n",
    "    num_of_epochs = 5\n",
    "    for epoch in range(num_of_epochs):\n",
    "        progress_bar = tqdm(loader, total=len(loader))\n",
    "        avg_loss = train_model(model, optimizer, device, criterion, progress_bar)\n",
    "        validate_progress = tqdm(val_loader, total=len(val_loader))\n",
    "        val_loss, val_f1 = validate_model(model, device, criterion, validate_progress)\n",
    "        print(f\"Epoch {epoch+1}: train loss = {avg_loss:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}: val loss = {val_loss:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}: val F1 = {val_f1:.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), f\"emotional_time_bert_{num_of_epochs}.pt\")\n"
   ],
   "id": "2ba4058df2574703",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T07:25:03.732387928Z",
     "start_time": "2025-12-18T07:25:03.302040797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_empath_data = pd.read_csv(\"empatheticdialogues/test.csv\", on_bad_lines=\"skip\")\n",
    "test_grouped = test_empath_data.groupby(\"conv_id\")\n",
    "test_conversations = []\n",
    "\n",
    "for conv_id, df_conv in test_grouped:\n",
    "    texts = df_conv[\"utterance\"].tolist()\n",
    "    # texts = (df_conv[\"prompt\"] + \"[SEP]\" + df_conv[\"utterance\"]).tolist()\n",
    "    labels = [emotion_to_id[x] for x in df_conv[\"context\"]]\n",
    "    timestamps = df_conv[\"utterance_idx\"].tolist()\n",
    "    speakers = (\n",
    "        df_conv[\"speaker_idx\"]\n",
    "        .rank(method=\"dense\")\n",
    "        .astype(int)\n",
    "        .sub(1)\n",
    "        .tolist()\n",
    "    )\n",
    "    test_conversations.append({\n",
    "        \"texts\": texts,\n",
    "        \"labels\": labels,\n",
    "        \"timestamps\": timestamps,\n",
    "        \"speakers\": speakers\n",
    "    })"
   ],
   "id": "ee8a807ea366a8e9",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T07:25:03.745680779Z",
     "start_time": "2025-12-18T07:25:03.737543573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_dataset = EmpatheticDialoguesDataset(test_conversations, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    collate_fn=lambda x: collate_conversations(x, tokenizer)\n",
    ")"
   ],
   "id": "7318ab3595e75852",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T07:25:09.863443449Z",
     "start_time": "2025-12-18T07:25:03.746115582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_f1 = test_model(\n",
    "    model=model,\n",
    "    dataloader=test_loader,\n",
    "    device=device,\n",
    "    emotion_labels=emotion_labels\n",
    ")"
   ],
   "id": "9770b5294e8eb6b5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/80 [00:00<?, ?it/s]/home/cayden/miniconda3/lib/python3.13/site-packages/torch/nn/modules/transformer.py:515: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  output = torch._nested_tensor_from_mask(\n",
      "Testing: 100%|██████████| 80/80 [00:06<00:00, 13.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro F1: 0.4205\n",
      "\n",
      "Per-emotion results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " sentimental      0.403     0.415     0.409       205\n",
      "      afraid      0.309     0.262     0.284       164\n",
      "       proud      0.630     0.308     0.413       221\n",
      "    faithful      0.733     0.282     0.407       117\n",
      "   terrified      0.326     0.548     0.409       155\n",
      "      joyful      0.311     0.171     0.221       187\n",
      "       angry      0.252     0.149     0.188       181\n",
      "         sad      0.356     0.477     0.408       195\n",
      "     jealous      0.564     0.579     0.571       183\n",
      "    grateful      0.583     0.380     0.460       221\n",
      "    prepared      0.450     0.595     0.512       173\n",
      " embarrassed      0.584     0.642     0.612       179\n",
      "     excited      0.389     0.624     0.479       202\n",
      "     annoyed      0.385     0.616     0.474       198\n",
      "      lonely      0.545     0.772     0.639       171\n",
      "     ashamed      0.315     0.161     0.213       143\n",
      "      guilty      0.385     0.638     0.480       149\n",
      "   surprised      0.513     0.529     0.521       291\n",
      "   nostalgic      0.632     0.428     0.510       173\n",
      "   confident      0.423     0.371     0.395       170\n",
      "     furious      0.243     0.222     0.232       153\n",
      "disappointed      0.403     0.309     0.349       188\n",
      "      caring      0.395     0.672     0.498       177\n",
      "    trusting      0.409     0.456     0.431       147\n",
      "   disgusted      0.682     0.621     0.650       190\n",
      "anticipating      0.547     0.247     0.340       166\n",
      "     anxious      0.285     0.240     0.260       171\n",
      "     hopeful      0.526     0.343     0.415       175\n",
      "     content      0.606     0.465     0.526       172\n",
      "   impressed      0.533     0.404     0.460       178\n",
      "apprehensive      0.218     0.475     0.299       158\n",
      "  devastated      0.589     0.291     0.389       148\n",
      "\n",
      "    accuracy                          0.433      5701\n",
      "   macro avg      0.454     0.428     0.420      5701\n",
      "weighted avg      0.456     0.433     0.426      5701\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T07:25:09.886060762Z",
     "start_time": "2025-12-18T07:25:09.883059665Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2767ae8b628b18c5",
   "outputs": [],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
